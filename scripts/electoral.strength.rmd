---
author: "Max Blasdel"
date: "January 12, 2019"
title: "Electoral Data Scraping"
---

# Script for collecting and preparing data for HTML voting project
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load relavent packages
```{r warning=F, message=FALSE}
require(rvest) # for web scraping
require(sf)
require(geojsonio)
require(jsonlite)
require(magrittr)
require(dplyr)
```

Establish initial website to pull data from. Wikipedia is great for this becuase of how they structure their data and webpage.
```{r}
webpage <- read_html("https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population")
```


Below I read in the entire table as it appears on the webpage at once and clean it in the R environment. This is easier than trying to take indivual columns of interest.
```{r}
# Full table
table <- html_nodes(webpage, "table")

# Read as table
table <- html_table(table, header = T)

# Only take first table as others are not needed
table <- table[[1]]

# Remove first two columns which are unneeded
table[,1:2]<-NULL

# Remove commas and percent sign. This drops one column which has number of reps due to special characters
table[,-1] <- as.numeric(gsub(",|%", "" , as.matrix(table[,-1])))
# only concerned with states, DC and Puerto Rico
table <- table[1:52,]
```

Explore the data
```{r}
table %>% head()
```


Clean data some more before transfer to JSON
```{r}
# Drop column of representatives which is full of NA values
table[,5]<-NULL

# Shorten and simplify colnames
colnames(table)<- c("name", "pop2018", "pop2010", "percentChange", "popPerElectoralVote", "popPerHouseSeat", "censusPerHouseSeat", "perTotalPopulation")
```

Read in a csv with electoral vote totals for each state. This could also be done rvest and a different wiki page, but I knew I had this data from a past project.
```{r}
#read in document that has electoral votes to add to dataset
votingPower <- read.csv("../data/voting power/Electoral Info.csv", stringsAsFactors = F) %>% select(state, Electoral.Votes)

votingPower %<>% 
  rename(electoralVotes = Electoral.Votes)

# Join with data of electoral votes
table <- left_join(table, votingPower, by= c("name"="state"))
```

Need to change some of the data for Puerto Rico since it is an outlier in a lot of regards. Some values are added to Puerto Rico just so it can be seen on a graph later on.
```{r}
# change Puerto Rice NA to 0
table[is.na(table)] <- 0

# arrange in order
table %<>% arrange(name)

# Adding value to the Puerto Rico Electoral Vote so it can be seen on the graph
table[40,]$popPerElectoralVote<-30000
```

Calculate Electoral Votes based soley on Population including PR
```{r}
# Get the total number of electoral votes
eVotes <- table$electoralVotes %>% sum()
table$pop2018 %>% sum()

# Calculate proportional votes based on population
table %<>% 
  mutate(proportionalElectoral = round(eVotes*(pop2018/sum(pop2018)), 2))

# Rounding errors introduce some loss in the proportional votes total
table$proportionalElectoral %>% sum()
```


Write out for use as javascript variable.
During development I was able to write the file to the folder that my HTML was reading. This means I could make a change to the data in R, save the data here, and have that change show up on the voting project HTML. Once this was uploaded to a server the process is not as seemless. 
```{r eval=FALSE}
# Write out for js useage
writeLines(paste("var voting =", toJSON(table, pretty = T), sep = " "), "../data/js/voting_update.js")
```


# Mapping Portion for the leaflet map

Read in state data. Data comes from Natural Earth.
```{r}
states <- st_read("../data/states", layer = "ne_10m_admin_1_states_provinces_lakes")

# Filter for the US 
us<-states %>% 
  filter(adm0_a3 == "USA")

# Select Puerto Rico
pr<-states %>% 
  filter(name == "Puerto Rico")

# Bind together
us <- rbind(pr, us)

# Remove unneeded attributes and leave only name
us %<>% select(name)
```


Join some attributes that may be useful
```{r}
us<-left_join(us, table, by="name")

# I really just want some of the population data from the map
us <- us[,1:4]
us %>% head()
```
Create seperate objects for Alaska, Hawaii, Puerto Rico
```{r}
pr <- us %>% 
  filter(name == 'Puerto Rico')
ak <- us %>% 
  filter(name == 'Alaska')
hi <- us %>% 
  filter(name == 'Hawaii')
```

Convert to spatial object and then geojson object.
Simple function to do both operations.
```{r}
toGeoJSON <- function(object){
  shape <- sf::as_Spatial(object)
  geojson <- geojsonio::geojson_json(shape)
  return(geojson)
}
```

Convert each object to a GeoJSON.
```{r}
us <- toGeoJSON(us)
pr <- toGeoJSON(pr)
ak <- toGeoJSON(ak)
hi <- toGeoJSON(hi)
```

Write out for js usage
```{r eval=FALSE}
writeLines(paste("var states = ", us), "../data/js/states.js")

writeLines(paste("var ak = ", ak), "../data/js/alaska.js")

writeLines(paste("var hi = ", hi), "../data/js/hawaii.js")

writeLines(paste("var pr = ", pr), "../data/js/puertorico.js")
```




